<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Viny Brasil&#39;s blog</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Viny Brasil&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Optimizing Python with Zig for numerical calculations</title>
      <link>http://localhost:1313/posts/zig-python-runge-kutta/</link>
      <pubDate>Mon, 28 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/zig-python-runge-kutta/</guid>
      
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;As a interpreted language, Python is known for being slower than compiled languages when running almost all processes including numerical calculations. It&amp;rsquo;s a trade-off actually, since writing
compiled languages is normally more complicated (having to deal with pointers, for example) than Python.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s a way of profiting from both of the good parts of the languages: using dynamically linked shared object libraries. Compiling a function used in the calculation from the compiled language code to a shared object and loading it in Python, where we&amp;rsquo;ll call the function with the parameters, is
normally faster than just pure Python.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Caching API responses with Redis in Zig</title>
      <link>http://localhost:1313/posts/cache-zig-redis/</link>
      <pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/cache-zig-redis/</guid>
      
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When fetching a database, our server must perform a READ operation. Every transation has a cost of time and money (computational cost in the cloud). One way of reducing this cost it&amp;rsquo;s
to cache the last record fetched so we don&amp;rsquo;t have to perform another READ operation. This can help when the same record is requested multiple times.&lt;/p&gt;
&lt;p&gt;To do this caching, we can use Redis, a advanced key-value store that works as a in memory database. It is really fast and combines with our choice for the backend: &lt;code&gt;zap&lt;/code&gt;, a blazingly fast
webframework written in Zig.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Running sklearn models in Zig</title>
      <link>http://localhost:1313/posts/zig-sklearn/</link>
      <pubDate>Thu, 06 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/zig-sklearn/</guid>
      
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Scikit-learn models became the industry standard for creating machine learning models.
Although the library offers many conveniences, one becomes tied to Python APIs for serving such models. These frameworks (such as FastAPI, for example) have various scalability issues, as Anton demonstrates in this video.
To overcome this limitation, one solution is to use Python&amp;rsquo;s C library to run the models, while the rest of the API can be built using another framework.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Building a real-time Websocket webapp with Kafka and Javascript</title>
      <link>http://localhost:1313/posts/websockets-kafka/</link>
      <pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/websockets-kafka/</guid>
      
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Suppose we have a API that generates a lot of information whom we must store in a database and show them to clients. This information updates every few seconds
and this sort of system is call a real-time app (in reality, it takes some seconds, so it&amp;rsquo;s a near real time app). Some applications that can use this sort of design are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;chatbots: the API is a LLM that receives an input and send it&amp;rsquo;s response to the client;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Convert decimal odds to probabilities with Zig</title>
      <link>http://localhost:1313/posts/zigodd/</link>
      <pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/zigodd/</guid>
      
      <description>&lt;p&gt;A Zig program for conversion and payout calculation&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;As sports betting expands across the world, more and more players don&amp;rsquo;t understand tha math
behind it. So, the purpose of this article it&amp;rsquo;s to clarify how to convert from decimal odds
to the probability behind them. The calculations are implemented in Zig, a system programming
language perfect to create CLI tools because it&amp;rsquo;s fast and simple.&lt;/p&gt;
&lt;p&gt;This article it&amp;rsquo;s divided into two sections: first we&amp;rsquo;ll talk about the math and them about the
implementation. If you only need the code you can go directly to my &lt;a href=&#34;https://github.com/vinybrasil/zigodd&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Trigger a AWS Lambda with a SQS message with Python</title>
      <link>http://localhost:1313/posts/sqs-lambda/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/sqs-lambda/</guid>
      
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the context of microservices, the communication of them must be fast and realiabe. This communication can be through messages and a tool for this communication can be SQS (Simple Queue Service), a messaging service by AWS.&lt;/p&gt;
&lt;p&gt;This project will be a example of a system that can receive a SQS message from a client, process it, and give the information to another client. As a example of this process, we&amp;rsquo;ll create a microservice in a AWS Lambda that will act when receive a SQS message. It&amp;rsquo;ll write the message in a .txt file and return all the messages when receives a HTTP call to a certain endpoint. We&amp;rsquo;ll be using AWS Lambda because it is a serverless framework, in which the idea is you don&amp;rsquo;t have to worry about servers.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Deploying a classification model on AWS Lambda with Docker and FastAPI</title>
      <link>http://localhost:1313/posts/classification-model/</link>
      <pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/classification-model/</guid>
      
      <description>&lt;p&gt;Does the user inserted the correct picture when the app requested? That&amp;rsquo;s a pretty common problem companies faces when creating a onboarding process of a app or a web service. For example, during the onboarding process of a bank the app can ask for a selfie and the user insert a picture of it&amp;rsquo;s ID. Since in those kind of processes there&amp;rsquo;s a huge amount of requests at the same time, a manual validation process can&amp;rsquo;t be used and a machine learning model can be a good alternative. TensorFlow and FastAPI can be used to create that solution.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>An asynchronous Consumer and Producer API for Kafka with FastAPI in Python</title>
      <link>http://localhost:1313/posts/kafka-python-consumer-producer/</link>
      <pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/kafka-python-consumer-producer/</guid>
      
      <description>&lt;p&gt;Writing asynchronous code it&amp;rsquo;s worth the effort when you&amp;rsquo;re dealing with a high load or multiple microservices that can take some time to answer your calls. The purpose of this article is to create an simple asynchronous API that works the same time as a Kafka&amp;rsquo;s producer and consumer. The full project it&amp;rsquo;s on my &lt;a href=&#34;https://github.com/vinybrasil/fastapi_kafka&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;setting-up-kafka&#34;&gt;Setting up Kafka&lt;/h3&gt;
&lt;p&gt;In this tutorial we&amp;rsquo;ll be using Docker to set up Kafka following the &lt;a href=&#34;https://towardsdatascience.com/kafka-docker-python-408baf0e1088&#34;&gt;Shuyi Yang&amp;rsquo;s tutorial[1]&lt;/a&gt;. The docker-compose.yml file used will be:&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
